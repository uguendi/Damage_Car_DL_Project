{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP CELL - RUN THIS FIRST\n",
    "import os\n",
    "\n",
    "# Automatic Path setup\n",
    "# This approach verifies where we are and points to the project root\n",
    "# so that imports and data loading work correctly.\n",
    "\n",
    "target_file = 'best.pt' # Marker file to identify root\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    print(f'Success: Found {target_file} in current directory.')\n",
    "    print('Ready to run.')\n",
    "elif os.path.exists(os.path.join('..', target_file)):\n",
    "    print(f'Found {target_file} in parent directory. Changing directory to root...')\n",
    "    os.chdir('..')\n",
    "    print(f'Current Working Directory: {os.getcwd()}')\n",
    "else:\n",
    "    print('WARNING: Could not find project root (best.pt not found).')\n",
    "    print('Please ensure you have downloaded the necessary files from Drive and placed them correctly.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def label_cropped_dataset(\n",
    "    source_dir=\"cropped_damages\",\n",
    "    resnet_path=\"severity_model_resnet18.pth\",\n",
    "    output_dir=\"cropped_damages_results\",\n",
    "    class_names=['high', 'low', 'medium'] # Must match training order\n",
    "):\n",
    "    # Setup Device\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load ResNet\n",
    "    print(\"Loading ResNet model...\")\n",
    "    resnet_model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = resnet_model.fc.in_features\n",
    "    resnet_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "    resnet_model.load_state_dict(torch.load(resnet_path, map_location=device))\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    resnet_model.eval()\n",
    "\n",
    "    # Transforms (Match validation)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Setup Paths\n",
    "    source_path = Path(source_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "    image_files = [\n",
    "        p for p in source_path.rglob(\"*\") \n",
    "        if p.suffix.lower() in image_extensions\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(image_files)} images in {source_dir}. Starting labeling...\")\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Labeling\"):\n",
    "        try:\n",
    "            # Read Image (OpenCV)\n",
    "            original_image = cv2.imread(str(img_path))\n",
    "            if original_image is None:\n",
    "                continue\n",
    "\n",
    "            # Convert to PIL for Torch\n",
    "            image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(image_rgb)\n",
    "\n",
    "            # Inference\n",
    "            input_tensor = preprocess(pil_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = resnet_model(input_tensor)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                severity_idx = preds.item()\n",
    "                severity_label = class_names[severity_idx]\n",
    "                confidence = torch.nn.functional.softmax(outputs, dim=1)[0][severity_idx].item()\n",
    "\n",
    "            # Colors\n",
    "            color = (0, 255, 0) # Default Green\n",
    "            if severity_label == 'high':\n",
    "                color = (0, 0, 255) # Red\n",
    "            elif severity_label == 'medium':\n",
    "                color = (0, 165, 255) # Orange (BGR)\n",
    "            elif severity_label == 'low':\n",
    "                color = (0, 255, 255) # Yellow\n",
    "\n",
    "            # Draw Annotation\n",
    "            h, w = original_image.shape[:2]\n",
    "            \n",
    "            # Thick Border\n",
    "            cv2.rectangle(original_image, (0, 0), (w-1, h-1), color, 4)\n",
    "            \n",
    "            # Text Label with Background\n",
    "            label_text = f\"{severity_label} ({confidence:.2f})\"\n",
    "            (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            \n",
    "            # Ensure text fits inside or put at top left\n",
    "            cv2.rectangle(original_image, (0, 0), (tw + 4, th + 8), color, -1)\n",
    "            cv2.putText(original_image, label_text, (2, 15), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Save\n",
    "            save_name = output_path / img_path.name\n",
    "            cv2.imwrite(str(save_name), original_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nLabeling complete! Check outputs in {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    label_cropped_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}