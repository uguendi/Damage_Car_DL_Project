{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:14:33.679093Z",
     "iopub.status.busy": "2025-12-28T19:14:33.674682Z",
     "iopub.status.idle": "2025-12-28T19:14:33.682854Z",
     "shell.execute_reply": "2025-12-28T19:14:33.683074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best.pt in parent directory. Changing directory to root...\n",
      "Current Working Directory: /Users/ugurendirlik/DL Project/Damage_Car_DL_Project-1/project_part3\n"
     ]
    }
   ],
   "source": [
    "# SETUP CELL - RUN THIS FIRST\n",
    "import os\n",
    "\n",
    "# Automatic Path setup\n",
    "# This approach verifies where we are and points to the project root\n",
    "# so that imports and data loading work correctly.\n",
    "\n",
    "target_file = 'best.pt' # Marker file to identify root\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    print(f'Success: Found {target_file} in current directory.')\n",
    "    print('Ready to run.')\n",
    "elif os.path.exists(os.path.join('..', target_file)):\n",
    "    print(f'Found {target_file} in parent directory. Changing directory to root...')\n",
    "    os.chdir('..')\n",
    "    print(f'Current Working Directory: {os.getcwd()}')\n",
    "else:\n",
    "    print('WARNING: Could not find project root (best.pt not found).')\n",
    "    print('Please ensure you have downloaded the necessary files from Drive and placed them correctly.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T19:14:33.697075Z",
     "iopub.status.busy": "2025-12-28T19:14:33.684691Z",
     "iopub.status.idle": "2025-12-28T19:15:12.875673Z",
     "shell.execute_reply": "2025-12-28T19:15:12.876212Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Classes: ['high', 'low', 'medium']\n",
      "Dataset sizes: {'train': 180, 'val': 45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.1112 Acc: 0.4056\n",
      "val Loss: 1.1476 Acc: 0.4000\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 1.0563 Acc: 0.4111\n",
      "val Loss: 1.0925 Acc: 0.4889\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.8107 Acc: 0.6444\n",
      "val Loss: 0.9933 Acc: 0.5778\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6622 Acc: 0.7056\n",
      "val Loss: 0.8265 Acc: 0.6000\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 0.7944\n",
      "val Loss: 0.8873 Acc: 0.6000\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.4607 Acc: 0.8611\n",
      "val Loss: 0.9367 Acc: 0.6444\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.4166 Acc: 0.8444\n",
      "val Loss: 0.8925 Acc: 0.6667\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.3235 Acc: 0.9111\n",
      "val Loss: 0.8515 Acc: 0.6667\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.2639 Acc: 0.9556\n",
      "val Loss: 0.8342 Acc: 0.6667\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.2416 Acc: 0.9500\n",
      "val Loss: 0.8569 Acc: 0.6889\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.2805 Acc: 0.9278\n",
      "val Loss: 0.8510 Acc: 0.6667\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.2568 Acc: 0.9556\n",
      "val Loss: 0.8684 Acc: 0.6444\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.2097 Acc: 0.9611\n",
      "val Loss: 0.8636 Acc: 0.6889\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.2427 Acc: 0.9333\n",
      "val Loss: 0.8682 Acc: 0.6667\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.2495 Acc: 0.9611\n",
      "val Loss: 0.8700 Acc: 0.6889\n",
      "Training complete in 0m 34s\n",
      "Best val Acc: 0.6889\n",
      "Model saved to severity_model_resnet18.pth\n",
      "\n",
      "Evaluating on Validation Set (Detailed Report)...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.65      0.87      0.74        15\n",
      "         low       0.72      0.76      0.74        17\n",
      "      medium       0.71      0.38      0.50        13\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.70      0.67      0.66        45\n",
      "weighted avg       0.70      0.69      0.67        45\n",
      "\n",
      "Confusion matrix saved as 'confusion_matrix.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def train_model():\n",
    "    # Configuration\n",
    "    DATA_DIR = 'severity_data'\n",
    "    MODEL_SAVE_PATH = 'severity_model_resnet18.pth'\n",
    "    NUM_CLASSES = 3  # low, medium, high\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_EPOCHS = 15\n",
    "    LEARNING_RATE = 0.001\n",
    "    DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # Use M2 GPU (MPS) if available\n",
    "    \n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    # Data Transforms\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # Load Dataset\n",
    "    full_dataset = datasets.ImageFolder(DATA_DIR, transform=data_transforms['train'])\n",
    "    class_names = full_dataset.classes\n",
    "    print(f\"Classes: {class_names}\")\n",
    "\n",
    "    # Split Train/Val (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # Apply 'val' transform to validation dataset (hacky way because random_split doesn't support different transforms)\n",
    "    # We will just accept that val set has some augmentation or strictly reload if needed. \n",
    "    # For simplicity/speed here, we use the same dataset object. \n",
    "    # Ideally we'd wrap it to override transform, but for this project data augmentation on val (except resize) is minimal\n",
    "    # actually, ImageFolder applies transform at loading time.\n",
    "    # To do it properly: create two dataset objects pointing to same folder, one with train transform, one with val transform,\n",
    "    # then split indices.\n",
    "    \n",
    "    # Proper Reset for transforms\n",
    "    train_dataset.dataset.transform = data_transforms['train']\n",
    "    # Create a new validation dataset with correct transform\n",
    "    # We can't easily deepcopy just the transform of a Subset, so let's stick to the simple split \n",
    "    # and just remember validation metrics will be slightly \"harder\" due to augmentation or we ignore it for now.\n",
    "    # Given the small dataset, data augmentation on validation isn't fatal, but let's correct it for best practice.\n",
    "    \n",
    "    # Reloading specifically for clean split logic\n",
    "    full_data_train = datasets.ImageFolder(DATA_DIR, transform=data_transforms['train'])\n",
    "    full_data_val = datasets.ImageFolder(DATA_DIR, transform=data_transforms['val'])\n",
    "    \n",
    "    # Use consistent seed for splitting indices\n",
    "    torch.manual_seed(42)\n",
    "    indices = torch.randperm(len(full_data_train)).tolist()\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(full_data_train, train_indices)\n",
    "    val_subset = torch.utils.data.Subset(full_data_val, val_indices)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True),\n",
    "        'val': DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    }\n",
    "    dataset_sizes = {'train': len(train_subset), 'val': len(val_subset)}\n",
    "    print(f\"Dataset sizes: {dataset_sizes}\")\n",
    "\n",
    "    # Initialize Model (ResNet18)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # Training Loop\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'Epoch {epoch}/{NUM_EPOCHS - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # Fix for MPS: Use .float() instead of .double() or cast result to cpu first\n",
    "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    print(\"\\nEvaluating on Validation Set (Detailed Report)...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Classification Report\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Validation Set')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    print(\"Confusion matrix saved as 'confusion_matrix.png'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}