{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:56:20.667857Z",
     "iopub.status.busy": "2025-12-28T18:56:20.667437Z",
     "iopub.status.idle": "2025-12-28T18:56:20.671619Z",
     "shell.execute_reply": "2025-12-28T18:56:20.671840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best.pt in parent directory. Changing directory to root...\n",
      "Current Working Directory: /Users/ugurendirlik/DL Project/Damage_Car_DL_Project-1/project_part3\n"
     ]
    }
   ],
   "source": [
    "# SETUP CELL - RUN THIS FIRST\n",
    "import os\n",
    "\n",
    "# Automatic Path setup\n",
    "# This approach verifies where we are and points to the project root\n",
    "# so that imports and data loading work correctly.\n",
    "\n",
    "target_file = 'best.pt' # Marker file to identify root\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    print(f'Success: Found {target_file} in current directory.')\n",
    "    print('Ready to run.')\n",
    "elif os.path.exists(os.path.join('..', target_file)):\n",
    "    print(f'Found {target_file} in parent directory. Changing directory to root...')\n",
    "    os.chdir('..')\n",
    "    print(f'Current Working Directory: {os.getcwd()}')\n",
    "else:\n",
    "    print('WARNING: Could not find project root (best.pt not found).')\n",
    "    print('Please ensure you have downloaded the necessary files from Drive and placed them correctly.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:56:20.682763Z",
     "iopub.status.busy": "2025-12-28T18:56:20.682335Z",
     "iopub.status.idle": "2025-12-28T18:56:40.212349Z",
     "shell.execute_reply": "2025-12-28T18:56:40.212593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading YOLO model...\n",
      "Loading ResNet model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 images in In_Person. Starting pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                                                                                                                                                                             | 0/24 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete! Check outputs in In_Person_Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def run_pipeline(\n",
    "    source_dir=\"In_Person\",\n",
    "    yolo_path=\"best.pt\",\n",
    "    resnet_path=\"severity_model_resnet18.pth\",\n",
    "    output_dir=\"In_Person_Results\",\n",
    "    class_names=['high', 'low', 'medium'] # Must match training order! Alphabetical usually by ImageFolder\n",
    "):\n",
    "    # Setup Device\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 1. Load YOLO\n",
    "    print(\"Loading YOLO model...\")\n",
    "    yolo_model = YOLO(yolo_path)\n",
    "\n",
    "    # 2. Load ResNet\n",
    "    print(\"Loading ResNet model...\")\n",
    "    resnet_model = models.resnet18(pretrained=False) # No need to download weights, we load ours\n",
    "    num_ftrs = resnet_model.fc.in_features\n",
    "    resnet_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "    resnet_model.load_state_dict(torch.load(resnet_path, map_location=device))\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    resnet_model.eval()\n",
    "\n",
    "    # Transforms for ResNet (Must match validation transforms)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 3. Process Images\n",
    "    source_path = Path(source_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "    image_files = [\n",
    "        p for p in source_path.rglob(\"*\") \n",
    "        if p.suffix.lower() in image_extensions\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(image_files)} images in {source_dir}. Starting pipeline...\")\n",
    "\n",
    "    for img_path in tqdm(image_files, desc=\"Processing\"):\n",
    "        try:\n",
    "            # Read Image\n",
    "            original_image = cv2.imread(str(img_path))\n",
    "            if original_image is None:\n",
    "                print(f\"Failed to load {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # YOLO Inference\n",
    "            results = yolo_model(original_image, verbose=False)\n",
    "\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "                \n",
    "                for box in boxes:\n",
    "                    # Get Box Coords\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    \n",
    "                    # Crop for Severity Check\n",
    "                    # Ensure within bounds\n",
    "                    h, w = original_image.shape[:2]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(w, x2), min(h, y2)\n",
    "                    \n",
    "                    crop = original_image[y1:y2, x1:x2]\n",
    "                    if crop.size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Prepare Crop for ResNet\n",
    "                    # Convert BGR (OpenCV) to RGB (PIL/Torch)\n",
    "                    crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "                    pil_img = Image.fromarray(crop_rgb)\n",
    "                    \n",
    "                    input_tensor = preprocess(pil_img).unsqueeze(0).to(device)\n",
    "                    \n",
    "                    # ResNet Inference\n",
    "                    with torch.no_grad():\n",
    "                        outputs = resnet_model(input_tensor)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        severity_idx = preds.item()\n",
    "                        severity_label = class_names[severity_idx]\n",
    "                        confidence = torch.nn.functional.softmax(outputs, dim=1)[0][severity_idx].item()\n",
    "\n",
    "                    # Draw on Image\n",
    "                    # Color based on severity?\n",
    "                    color = (0, 255, 0) # Green default\n",
    "                    if severity_label == 'high':\n",
    "                        color = (0, 0, 255) # Red\n",
    "                    elif severity_label == 'medium':\n",
    "                        color = (0, 165, 255) # Orange (BGR)\n",
    "                    elif severity_label == 'low':\n",
    "                        color = (0, 255, 255) # Yellow\n",
    "                        \n",
    "                    # Draw Box\n",
    "                    cv2.rectangle(original_image, (x1, y1), (x2, y2), color, 2)\n",
    "                    \n",
    "                    # Draw Label\n",
    "                    label_text = f\"{severity_label} ({confidence:.2f})\"\n",
    "                    # Get text size\n",
    "                    (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                    # Text background\n",
    "                    cv2.rectangle(original_image, (x1, y1 - 20), (x1 + tw, y1), color, -1)\n",
    "                    # Text\n",
    "                    cv2.putText(original_image, label_text, (x1, y1 - 5), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "            # Save Result\n",
    "            save_name = output_path / img_path.name\n",
    "            cv2.imwrite(str(save_name), original_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nProcessing complete! Check outputs in {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
