{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP CELL - RUN THIS FIRST\n",
    "import os\n",
    "\n",
    "# Automatic Path setup\n",
    "# This approach verifies where we are and points to the project root\n",
    "# so that imports and data loading work correctly.\n",
    "\n",
    "target_file = 'best.pt' # Marker file to identify root\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    print(f'Success: Found {target_file} in current directory.')\n",
    "    print('Ready to run.')\n",
    "elif os.path.exists(os.path.join('..', target_file)):\n",
    "    print(f'Found {target_file} in parent directory. Changing directory to root...')\n",
    "    os.chdir('..')\n",
    "    print(f'Current Working Directory: {os.getcwd()}')\n",
    "else:\n",
    "    print('WARNING: Could not find project root (best.pt not found).')\n",
    "    print('Please ensure you have downloaded the necessary files from Drive and placed them correctly.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crop_damages(\n",
    "    source_dir=\"dataset_raw_bing\",\n",
    "    model_path=\"best.pt\",\n",
    "    output_dir=\"cropped_damages\",\n",
    "    conf_threshold=0.25\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects damages using YOLOv8 and crops them into individual images.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    # Get list of all image files\n",
    "    source_path = Path(source_dir)\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "    image_files = [\n",
    "        p for p in source_path.rglob(\"*\") \n",
    "        if p.suffix.lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {source_dir}. Starting processing...\")\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for img_path in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        try:\n",
    "            # Run inference\n",
    "            results = model.predict(source=str(img_path), conf=conf_threshold, verbose=False)\n",
    "            \n",
    "            for r in results:\n",
    "                # Load original image for cropping\n",
    "                # Note: ultralytics might resize, so we use the original image from the prediction result or reload\n",
    "                # r.orig_img is the original numpy array\n",
    "                orig_img = r.orig_img\n",
    "                \n",
    "                boxes = r.boxes\n",
    "                for i, box in enumerate(boxes):\n",
    "                    # Bounding box coordinates\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    \n",
    "                    # Ensure coordinates are within image bounds\n",
    "                    h, w = orig_img.shape[:2]\n",
    "                    x1 = max(0, x1)\n",
    "                    y1 = max(0, y1)\n",
    "                    x2 = min(w, x2)\n",
    "                    y2 = min(h, y2)\n",
    "                    \n",
    "                    # Crop\n",
    "                    crop = orig_img[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # Skip empty crops\n",
    "                    if crop.size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Get class name\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    cls_name = model.names[cls_id]\n",
    "                    \n",
    "                    # Create unique filename: originalName_class_conf_index.jpg\n",
    "                    # Use parent folder name to avoid collisions if filenames are same across folders\n",
    "                    parent_name = img_path.parent.name\n",
    "                    stem = img_path.stem\n",
    "                    file_name = f\"{parent_name}_{stem}_{cls_name}_{box.conf[0]:.2f}_{i}.jpg\"\n",
    "                    \n",
    "                    # Replace spaces and special chars in filename\n",
    "                    file_name = file_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "                    \n",
    "                    save_path = output_path / file_name\n",
    "                    \n",
    "                    cv2.imwrite(str(save_path), crop)\n",
    "                    count += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total damage crops saved: {count}\")\n",
    "    print(f\"Saved to: {output_path.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crop_damages()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}