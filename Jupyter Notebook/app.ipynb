{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP CELL - RUN THIS FIRST\n",
    "import os\n",
    "\n",
    "# Automatic Path setup\n",
    "# This approach verifies where we are and points to the project root\n",
    "# so that imports and data loading work correctly.\n",
    "\n",
    "target_file = 'best.pt' # Marker file to identify root\n",
    "\n",
    "if os.path.exists(target_file):\n",
    "    print(f'Success: Found {target_file} in current directory.')\n",
    "    print('Ready to run.')\n",
    "elif os.path.exists(os.path.join('..', target_file)):\n",
    "    print(f'Found {target_file} in parent directory. Changing directory to root...')\n",
    "    os.chdir('..')\n",
    "    print(f'Current Working Directory: {os.getcwd()}')\n",
    "else:\n",
    "    print('WARNING: Could not find project root (best.pt not found).')\n",
    "    print('Please ensure you have downloaded the necessary files from Drive and placed them correctly.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Model Setup ---\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load YOLO\n",
    "print(\"Loading YOLO model...\")\n",
    "yolo_model = YOLO(\"best.pt\")\n",
    "\n",
    "# Load ResNet\n",
    "print(\"Loading ResNet model...\")\n",
    "class_names = ['high', 'low', 'medium'] # Must match training\n",
    "resnet_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "resnet_model.load_state_dict(torch.load(\"severity_model_resnet18.pth\", map_location=device))\n",
    "resnet_model = resnet_model.to(device)\n",
    "resnet_model.eval()\n",
    "\n",
    "# Transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 2. Inference Function ---\n",
    "def process_image(input_img):\n",
    "    \"\"\"\n",
    "    Takes a PIL Image or numpy array from Gradio, \n",
    "    detects damages with YOLO, classifiers with ResNet, \n",
    "    and returns annotated image.\n",
    "    \"\"\"\n",
    "    if input_img is None:\n",
    "        return None\n",
    "\n",
    "    # Convert to OpenCV format (BGR)\n",
    "    # Gradio passes RGB numpy array by default\n",
    "    original_image = cv2.cvtColor(input_img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # YOLO Inference\n",
    "    results = yolo_model(original_image, verbose=False)\n",
    "    \n",
    "    detections = [] # To store list of (severity, label) for summary text\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # 1. Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            \n",
    "            # Crop\n",
    "            h, w = original_image.shape[:2]\n",
    "            cx1, cy1 = max(0, x1), max(0, y1)\n",
    "            cx2, cy2 = min(w, x2), min(h, y2)\n",
    "            crop = original_image[cy1:cy2, cx1:cx2]\n",
    "            \n",
    "            if crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            # 2. Severity Classification (ResNet)\n",
    "            crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)\n",
    "            pil_crop = Image.fromarray(crop_rgb)\n",
    "            input_tensor = preprocess(pil_crop).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = resnet_model(input_tensor)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                severity_idx = preds.item()\n",
    "                severity_label = class_names[severity_idx]\n",
    "                confidence = torch.nn.functional.softmax(outputs, dim=1)[0][severity_idx].item()\n",
    "            \n",
    "            # YOLO Class Name\n",
    "            yolo_cls_id = int(box.cls[0])\n",
    "            part_name = yolo_model.names[yolo_cls_id]\n",
    "\n",
    "            # 3. Visualization\n",
    "            # Color Coding\n",
    "            color = (0, 255, 0) # Green default\n",
    "            if severity_label == 'high':\n",
    "                color = (0, 0, 255) # Red (BGR)\n",
    "            elif severity_label == 'medium':\n",
    "                color = (0, 165, 255) # Orange\n",
    "            elif severity_label == 'low':\n",
    "                color = (0, 255, 255) # Yellow\n",
    "            \n",
    "            # Draw Box\n",
    "            cv2.rectangle(original_image, (x1, y1), (x2, y2), color, 3)\n",
    "            \n",
    "            # Label Text: \"Scratch - High\"\n",
    "            label_text = f\"{part_name.upper()} - {severity_label.upper()}\"\n",
    "            \n",
    "            detections.append(label_text)\n",
    "\n",
    "            # Draw Label Background\n",
    "            (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            cv2.rectangle(original_image, (x1, y1 - 25), (x1 + tw + 10, y1), color, -1)\n",
    "            \n",
    "            # Draw Text\n",
    "            cv2.putText(original_image, label_text, (x1 + 5, y1 - 5), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    # Convert back to RGB for Gradio display\n",
    "    final_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Summary String\n",
    "    summary = \"Detected Damages:\\n\" + \"\\n\".join(detections) if detections else \"No damages detected.\"\n",
    "\n",
    "    return final_image, summary\n",
    "\n",
    "# --- 3. UI Setup ---\n",
    "demo = gr.Interface(\n",
    "    fn=process_image,\n",
    "    inputs=gr.Image(label=\"Upload Car Image\"),\n",
    "    outputs=[\n",
    "        gr.Image(label=\"Analyzed Image\"),\n",
    "        gr.Textbox(label=\"Detection Summary\")\n",
    "    ],\n",
    "    title=\"Car Damage Severity Detection System\",\n",
    "    description=\"Upload an image of a damaged car. The system will detect the damage type (using YOLOv8) and classify its severity (High/Medium/Low using ResNet18).\",\n",
    "    theme=\"default\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}